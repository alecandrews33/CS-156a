{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from numpy import linalg\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "sns.set_context('notebook')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E_in = []\n",
    "support_vectors =[]\n",
    "\n",
    "# Loop through the values 0 - 9 for all digits.\n",
    "for i in range(10):\n",
    "    # Parse data into form [(x1, x2), y]\n",
    "    with open(\"features.train.txt\", \"r\") as train_set:\n",
    "        raw_data = [line.strip().split('\\t') for line in train_set]\n",
    "    \n",
    "    split = []\n",
    "    for point in raw_data:\n",
    "        split.append(point[0].split())\n",
    "    \n",
    "    train = []\n",
    "    for point in split:\n",
    "        train.append([np.array([float(point[1]), float(point[2])]), int(float(point[0]))])\n",
    "    \n",
    "    X_training = []\n",
    "    Y_training = []\n",
    "    \n",
    "    # Classification for digit vs all classifier. i iterates through all digits.\n",
    "    for point in train:\n",
    "        if point[1] == i:\n",
    "            point[1] = 1.0\n",
    "        else:\n",
    "            point[1] = -1.0\n",
    "        X_training.append(point[0])\n",
    "        Y_training.append(point[1])\n",
    "    \n",
    "    # Run svm package, with Q = 2 and C = 0.01\n",
    "    svm1 = svm.SVC(kernel = 'poly', degree = 2, C = 0.01, coef0 = 1.0, gamma = 1.0)\n",
    "    svm1.fit(X_training, Y_training)\n",
    "    support_vectors.append(len(svm1.support_vectors_))\n",
    "    \n",
    "    error = 0.0\n",
    "    \n",
    "    for point in train:\n",
    "        svm_prediction = svm1.predict([point[0]])\n",
    "        # Find errors when the prediction doesn't line up with actual classification.\n",
    "        if svm_prediction[0] != point[1]:\n",
    "            error += 1\n",
    "    error /= len(train)\n",
    "    \n",
    "    E_in.append((error, i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10588396653408312, 0),\n",
       " (0.014401316691811822, 1),\n",
       " (0.10026059525442327, 2),\n",
       " (0.09024825126868742, 3),\n",
       " (0.08942531888629818, 4),\n",
       " (0.07625840076807022, 5),\n",
       " (0.09107118365107666, 6),\n",
       " (0.08846523110684405, 7),\n",
       " (0.07433822520916199, 8),\n",
       " (0.08832807570977919, 9)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10588396653408312, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum error for 0, 2, 4, 6, and 8 vs all\n",
    "max(E_in[:9:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014401316691811822, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum error for 1, 3, 5, 7, and 9 vs all\n",
    "min(E_in[1:10:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_max = max(E_in[:9:2])[1]\n",
    "sv_min = min(E_in[1:10:2])[1]\n",
    "# Difference in number of support vectors from the answers to the last two problems.\n",
    "np.abs(support_vectors[sv_max] - support_vectors[sv_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_digit = 1.0\n",
    "second_digit = 5.0\n",
    "C_values = [0.001, 0.01, 0.1, 1]\n",
    "E_in = []\n",
    "E_out = []\n",
    "support_vectors = []\n",
    "\n",
    "# Loop through all C values\n",
    "for c in C_values:\n",
    "    with open(\"features.train.txt\", \"r\") as train_set:\n",
    "        raw_data = [line.strip().split('\\t') for line in train_set]\n",
    "    \n",
    "    split = []\n",
    "    for point in raw_data:\n",
    "        split.append(point[0].split())\n",
    "    \n",
    "    train = []\n",
    "    \n",
    "    # Parse data for 1 vs 5 classifier into training set\n",
    "    for point in split:\n",
    "        if float(point[0]) == first_digit:\n",
    "            train.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "        elif float(point[0]) == second_digit:\n",
    "            train.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "            \n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    for point in train:\n",
    "        X_train.append(point[0])\n",
    "        Y_train.append(point[1])\n",
    "        \n",
    "    with open('features.test.txt','r') as test_set:\n",
    "        raw_data = [line.strip().split('\\t') for line in test_set]\n",
    "        \n",
    "    split = []\n",
    "    for point in raw_data:\n",
    "        split.append(point[0].split())\n",
    "        \n",
    "    test = []\n",
    "    \n",
    "    # Parse data for 1 vs 5 classifier in test set\n",
    "    for point in split:\n",
    "        if float(point[0]) == first_digit:\n",
    "            test.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "        elif float(point[0]) == second_digit:\n",
    "            test.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "    \n",
    "    # Run svm package on Q = 2 and whatever values of c is currently at\n",
    "    svm1 = svm.SVC(kernel = 'poly', degree = 2, C = c, coef0 = 1.0, gamma = 1.0)\n",
    "    svm1.fit(X_train, Y_train)\n",
    "    # Keep track of support vectors required for the different values of C\n",
    "    support_vectors.append((len(svm1.support_vectors_), c))\n",
    "    \n",
    "    e_in = 0.0\n",
    "    for point in train:\n",
    "        # Run prediction on each point in training set and calculate classification error\n",
    "        svm_prediction = svm1.predict([point[0]])\n",
    "        if svm_prediction[0] != point[1]:\n",
    "            e_in += 1\n",
    "        \n",
    "    e_in /= len(train)\n",
    "    \n",
    "    E_in.append((e_in, c))\n",
    "    \n",
    "    e_out = 0.0\n",
    "    for point in test:\n",
    "        # Run predicition on each point in test set and calculate classification error\n",
    "        svm_prediction = svm1.predict([point[0]])\n",
    "        if svm_prediction[0] != point[1]:\n",
    "            e_out += 1\n",
    "    \n",
    "    e_out /= len(test)\n",
    "    \n",
    "    E_out.append((e_out, c))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01650943396226415, 0.001),\n",
       " (0.018867924528301886, 0.01),\n",
       " (0.018867924528301886, 0.1),\n",
       " (0.018867924528301886, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.004484304932735426, 0.001),\n",
       " (0.004484304932735426, 0.01),\n",
       " (0.004484304932735426, 0.1),\n",
       " (0.0032030749519538757, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(76, 0.001), (34, 0.01), (24, 0.1), (24, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_digit = 1.0\n",
    "second_digit = 5.0\n",
    "C_values = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "E_in1 = []\n",
    "E_in2 = []\n",
    "E_out1 = []\n",
    "E_out2 = []\n",
    "support_vectors1 = []\n",
    "support_vectors2 = []\n",
    "\n",
    "for c in C_values:\n",
    "    with open(\"features.train.txt\", \"r\") as train_set:\n",
    "        raw_data = [line.strip().split('\\t') for line in train_set]\n",
    "    \n",
    "    split = []\n",
    "    for point in raw_data:\n",
    "        split.append(point[0].split())\n",
    "    \n",
    "    train = []\n",
    "    # Parse data for 1 vs 5 classifier in training set\n",
    "    for point in split:\n",
    "        if float(point[0]) == first_digit:\n",
    "            train.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "        elif float(point[0]) == second_digit:\n",
    "            train.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "            \n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    for point in train:\n",
    "        X_train.append(point[0])\n",
    "        Y_train.append(point[1])\n",
    "        \n",
    "    with open('features.test.txt','r') as test_set:\n",
    "        raw_data = [line.strip().split('\\t') for line in test_set]\n",
    "        \n",
    "    split = []\n",
    "    for point in raw_data:\n",
    "        split.append(point[0].split())\n",
    "        \n",
    "    test = []\n",
    "    # Parse data for 1 vs 5 classifier in test set\n",
    "    for point in split:\n",
    "        if float(point[0]) == first_digit:\n",
    "            test.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "        elif float(point[0]) == second_digit:\n",
    "            test.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "    \n",
    "    # Run svm package on Q = 2 for all C values\n",
    "    svm1 = svm.SVC(kernel = 'poly', degree = 2, C = c, coef0 = 1.0, gamma = 1.0)\n",
    "    svm1.fit(X_train, Y_train)\n",
    "    support_vectors1.append((len(svm1.support_vectors_), c))\n",
    "    \n",
    "    # Run svm package on Q = 5 for all C values\n",
    "    svm2 = svm.SVC(kernel = 'poly', degree = 5, C = c, coef0 = 1.0, gamma = 1.0)\n",
    "    svm2.fit(X_train, Y_train)\n",
    "    support_vectors2.append((len(svm2.support_vectors_), c))\n",
    "    \n",
    "    e_in1 = 0.0\n",
    "    e_in2 = 0.0\n",
    "    for point in train:\n",
    "        # Calculate classification error for both svm predictions (Q = 2 and Q = 5)\n",
    "        svm_prediction1 = svm1.predict([point[0]])\n",
    "        svm_prediction2 = svm2.predict([point[0]])\n",
    "        if svm_prediction1[0] != point[1]:\n",
    "            e_in1 += 1\n",
    "        if svm_prediction2[0] != point[1]:\n",
    "            e_in2 += 1\n",
    "        \n",
    "    e_in1 /= len(train)\n",
    "    e_in2 /= len(train)\n",
    "    \n",
    "    E_in1.append((e_in1, c))\n",
    "    E_in2.append((e_in2, c))\n",
    "    \n",
    "    e_out1 = 0.0\n",
    "    e_out2 = 0.0\n",
    "    for point in test:\n",
    "        # Calculate classification error for both svm predictions (Q = 2 and Q = 5)\n",
    "        svm_prediction1 = svm1.predict([point[0]])\n",
    "        svm_prediction2 = svm2.predict([point[0]])\n",
    "        if svm_prediction1[0] != point[1]:\n",
    "            e_out1 += 1\n",
    "        if svm_prediction2[0] != point[1]:\n",
    "            e_out2 += 1\n",
    "    \n",
    "    e_out1 /= len(test)\n",
    "    e_out2 /= len(test)\n",
    "    \n",
    "    E_out1.append((e_out1, c))\n",
    "    E_out2.append((e_out2, c))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.008968609865470852, 0.0001),\n",
       " (0.004484304932735426, 0.001),\n",
       " (0.004484304932735426, 0.01),\n",
       " (0.004484304932735426, 0.1),\n",
       " (0.0032030749519538757, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.004484304932735426, 0.0001),\n",
       " (0.004484304932735426, 0.001),\n",
       " (0.003843689942344651, 0.01),\n",
       " (0.0032030749519538757, 0.1),\n",
       " (0.0032030749519538757, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_in2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01650943396226415, 0.0001),\n",
       " (0.01650943396226415, 0.001),\n",
       " (0.018867924528301886, 0.01),\n",
       " (0.018867924528301886, 0.1),\n",
       " (0.018867924528301886, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.018867924528301886, 0.0001),\n",
       " (0.02122641509433962, 0.001),\n",
       " (0.02122641509433962, 0.01),\n",
       " (0.018867924528301886, 0.1),\n",
       " (0.02122641509433962, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(236, 0.0001), (76, 0.001), (34, 0.01), (24, 0.1), (24, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vectors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(26, 0.0001), (25, 0.001), (23, 0.01), (25, 0.1), (21, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vectors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"features.train.txt\", \"r\") as train_set:\n",
    "    raw_data = [line.strip().split('\\t') for line in train_set]\n",
    "    \n",
    "split = []\n",
    "for point in raw_data:\n",
    "    split.append(point[0].split())\n",
    "    \n",
    "train = []\n",
    "# Parse data for 1 vs 5 classifier in training set\n",
    "for point in split:\n",
    "    if float(point[0]) == 1:\n",
    "        train.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "    elif float(point[0]) == 5:\n",
    "        train.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "        \n",
    "X_values = []\n",
    "Y_values = []\n",
    "\n",
    "for point in train:\n",
    "    X_values.append(point[0])\n",
    "    Y_values.append(point[1])\n",
    "\n",
    "# Initialize dictionary to keep track of wins for each value of C\n",
    "Cwins = {0.0001:0, 0.001:0, 0.01:0, 0.1:0, 1:0}\n",
    "\n",
    "C_values = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "# For 100 random runs\n",
    "for i in range(100):\n",
    "    E_cv_average = []\n",
    "    for c in C_values:\n",
    "        # Run svm package with Q = 2 and for all C values\n",
    "        svm1 = svm.SVC(kernel = 'poly', degree = 2, C = c, coef0 = 1.0, gamma = 1.0)\n",
    "        # Use KFold to split up data for training and validation. Shuffle = true for randomization.\n",
    "        kf = KFold(n_splits=10, shuffle = True)\n",
    "        E_cv_values = []\n",
    "        for i_train, i_test in kf.split(X_values):\n",
    "            X_train = []\n",
    "            Y_train = []\n",
    "            # Put the points set aside for training in lists\n",
    "            for j in i_train:\n",
    "                X_train.append(X_values[j])\n",
    "                Y_train.append(Y_values[j])\n",
    "            \n",
    "            svm1.fit(X_train, Y_train)\n",
    "            X_test = []\n",
    "            Y_test = []\n",
    "             \n",
    "            # Put the points set aside for testing in lists\n",
    "            for k in i_test:\n",
    "                X_test.append(X_values[k])\n",
    "                Y_test.append(Y_values[k])\n",
    "            \n",
    "            E_cv = 0.0\n",
    "            \n",
    "            for j in range(len(X_test)):\n",
    "                svm_prediction = svm1.predict([X_test[j]])\n",
    "                if svm_prediction[0] != Y_test[j]:\n",
    "                    E_cv += 1\n",
    "            E_cv /= len(X_test)\n",
    "            \n",
    "            E_cv_values.append(E_cv)\n",
    "        E_cv_average.append((np.mean(E_cv_values), c))\n",
    "    Cwins[min(E_cv_average)[1]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0001: 0, 0.001: 37, 0.01: 31, 0.1: 15, 1: 17}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cwins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0089702760084925687, 0.0001),\n",
       " (0.0044871794871794869, 0.001),\n",
       " (0.0044830965213130819, 0.01),\n",
       " (0.0038379879144210352, 0.1),\n",
       " (0.0057651478033643646, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_cv_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"features.train.txt\", \"r\") as train_set:\n",
    "    raw_data = [line.strip().split('\\t') for line in train_set]\n",
    "    \n",
    "split = []\n",
    "for point in raw_data:\n",
    "    split.append(point[0].split())\n",
    "    \n",
    "train = []\n",
    "# Parse data for 1 vs 5 classifier in training set\n",
    "for point in split:\n",
    "    if float(point[0]) == 1:\n",
    "        train.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "    elif float(point[0]) == 5:\n",
    "        train.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "        \n",
    "X_values = []\n",
    "Y_values = []\n",
    "\n",
    "for point in train:\n",
    "    X_values.append(point[0])\n",
    "    Y_values.append(point[1])\n",
    "    \n",
    "with open(\"features.test.txt\", \"r\") as test_set:\n",
    "    raw_data = [line.strip().split('\\t') for line in test_set]\n",
    "    \n",
    "split = []\n",
    "for point in raw_data:\n",
    "    split.append(point[0].split())\n",
    "    \n",
    "test = []\n",
    "# Parse data for 1 vs 5 classifier\n",
    "for point in split:\n",
    "    if float(point[0]) == 1:\n",
    "        test.append([np.array([float(point[1]), float(point[2])]), 1.0])\n",
    "    elif float(point[0]) == 5:\n",
    "        test.append([np.array([float(point[1]), float(point[2])]), -1.0])\n",
    "        \n",
    "C_values = [.01, 1, 100, 10 ** 4, 10 ** 6]\n",
    "E_in = []\n",
    "E_out = []\n",
    "\n",
    "for c in C_values:\n",
    "    # Use the rbf kernel for this svm\n",
    "    svm1 = svm.SVC(kernel = 'rbf', C = c, coef0 = 1.0, gamma = 1.0)\n",
    "    svm1.fit(X_values, Y_values)\n",
    "    \n",
    "    e_in = 0.0\n",
    "    \n",
    "    for i in range(len(Y_values)):\n",
    "        # Run svm_prediction on training set to find E_in\n",
    "        svm_prediction = svm1.predict([X_values[i]])\n",
    "        if svm_prediction[0] != Y_values[i]:\n",
    "            e_in += 1\n",
    "            \n",
    "    e_in /= len(X_values)\n",
    "    E_in.append((e_in, c))\n",
    "    \n",
    "    e_out = 0.0\n",
    "    \n",
    "    for point in test:\n",
    "        # Run svm prediction on test set to find E_out\n",
    "        svm_prediction = svm1.predict([point[0]])\n",
    "        if svm_prediction != point[1]:\n",
    "            e_out += 1\n",
    "    e_out /= len(test)\n",
    "    E_out.append((e_out, c))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.003843689942344651, 0.01),\n",
       " (0.004484304932735426, 1),\n",
       " (0.0032030749519538757, 100),\n",
       " (0.0025624599615631004, 10000),\n",
       " (0.0006406149903907751, 1000000)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.02358490566037736, 0.01),\n",
       " (0.02122641509433962, 1),\n",
       " (0.018867924528301886, 100),\n",
       " (0.02358490566037736, 10000),\n",
       " (0.02358490566037736, 1000000)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
