{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules for helper functions.\n",
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from numpy import matrix\n",
    "from numpy import linalg\n",
    "sns.set_context('notebook')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to create random points for the training set. Add the artificial coordinate x0.\n",
    "\n",
    "def PointGenerator(M):\n",
    "    x = []\n",
    "   \n",
    "    for i in range(M):\n",
    "        x_value = random.uniform(-1, 1)\n",
    "           \n",
    "        y_value = random.uniform(-1, 1)\n",
    "                    \n",
    "        new = [1, x_value, y_value]  \n",
    "                \n",
    "        x.append(new)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to classify the set of data points. Note now that the target function is no longer a line. Also,\n",
    "# noise is added by switching the outcome ten percent of the time.\n",
    "\n",
    "def PointClassifier(data_set):\n",
    "    y = []\n",
    "    for point in data_set:\n",
    "        if numpy.sign(point[1] ** 2 + point[2] ** 2 - 0.6) == -1:\n",
    "            y_n = -1\n",
    "        else:\n",
    "            y_n = 1\n",
    "        y.append(y_n)\n",
    "    for j in range(int(0.1 * len(y))):\n",
    "        selection = random.choice(y)\n",
    "        selection *= -1\n",
    "    return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same Linear Regression function as before. This time, the target function isn't a line, so the points won't be\n",
    "# linearly separable.\n",
    "\n",
    "def LinearRegression(N):\n",
    "    X = PointGenerator(N)\n",
    "    line = LineGenerator()\n",
    "    y = PointClassifier(X)\n",
    "    \n",
    "    y = matrix(y)\n",
    "    X = matrix(X)\n",
    "    X_trans_X = X.T * X    \n",
    "    Inverse = X_trans_X.I\n",
    "    X_transposed = matrix(X).T\n",
    "    dagger = Inverse * X_transposed\n",
    "    weight = dagger * y.T\n",
    "    counter = 0\n",
    "    weight_x = weight.T * X.T\n",
    "    for i in range(N):\n",
    "        if numpy.sign(weight_x.flat[i]) != y.flat[i]:\n",
    "            counter += 1\n",
    "    \n",
    "    E_in = counter / N\n",
    "    \n",
    "    return(line, weight, E_in, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5069960000000001\n"
     ]
    }
   ],
   "source": [
    "# This is the answer to Number 8. It is the average E_in for Linear Regression on data that isn't linearly separable.\n",
    "\n",
    "average = 0\n",
    "for i in range(1000):\n",
    "    result = LinearRegression(1000)\n",
    "    average += result[2]\n",
    "average = average / 1000\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This helper function creates random data points, but returns them in a new form. It is a nonlinear transformation.\n",
    "\n",
    "def NonlinearPointGenerator(M):\n",
    "    x = []\n",
    "   \n",
    "    for i in range(M):\n",
    "        x_value = random.uniform(-1, 1)\n",
    "           \n",
    "        y_value = random.uniform(-1, 1)\n",
    "                    \n",
    "        new = [1, x_value, y_value, x_value * y_value, x_value ** 2, y_value ** 2]  \n",
    "                \n",
    "        x.append(new)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will use the data points after they have gone through the nonlinear transformation, and then use\n",
    "# linear regression on the newly formatted points.\n",
    "\n",
    "def NonLinearRegression(N):\n",
    "    X = NonlinearPointGenerator(N)\n",
    "    line = LineGenerator()\n",
    "    y = PointClassifier(X)\n",
    "    \n",
    "    y = matrix(y)\n",
    "    X = matrix(X)\n",
    "    X_trans_X = X.T * X    \n",
    "    Inverse = X_trans_X.I\n",
    "    X_transposed = matrix(X).T\n",
    "    dagger = Inverse * X_transposed\n",
    "    weight = dagger * y.T\n",
    "    counter = 0\n",
    "    weight_x = weight.T * X.T\n",
    "    for i in range(N):\n",
    "        if numpy.sign(weight_x.flat[i]) != y.flat[i]:\n",
    "            counter += 1\n",
    "    \n",
    "    E_in = counter / N\n",
    "    \n",
    "    return(line, weight, E_in, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028328995999999933\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes, we find the average E_in for linear regression after the nonlinear transformation. We also \n",
    "# set the weight vector to what came out of the linear regression with these newly formatted points. This weight vector\n",
    "# will be used in number 9.\n",
    "\n",
    "for i in range(1000):\n",
    "    result = NonLinearRegression(1000)\n",
    "    average += result[2]\n",
    "average = average / 1000\n",
    "print(average)\n",
    "weight = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following functions simulate the functions outlined in the possible answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptionA(x1, x2):\n",
    "    return numpy.sign(-1 - .05 * x1 + .08 * x2 + 0.13 * x1 * x2 + 1.5 * x1**2 + 1.5 * x2**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OptionB(x1, x2):\n",
    "    return numpy.sign(-1 - .05 * x1 + .08 * x2 + 0.13 * x1 * x2 + 1.5 * x1**2 + 15 * x2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OptionC(x1, x2):\n",
    "    return numpy.sign(-1 - .05 * x1 + .08 * x2 + 0.13 * x1 * x2 + 15 * x1**2 + 1.5 * x2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OptionD(x1, x2):\n",
    "    return numpy.sign(-1 - 1.5 * x1 + .08 * x2 + 0.13 * x1 * x2 + .05 * x1**2 + .05 * x2**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OptionE(x1, x2):\n",
    "    return numpy.sign(-1 - .05 * x1 + .08 * x2 + 1.5 * x1 * x2 + 0.15 * x1**2 + 0.15 * x2**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "71\n",
      "65\n",
      "61\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# We will see which hypothesis agree with our weight vector on the most points out of 100 random data points.\n",
    "# It prints the number of matching outcomes in the order of the answers, alphabetically. Answer to number 9. Recall\n",
    "# that this weight vector was generated earlier, and it is approximating our function after the nonlinear \n",
    "# transformation.\n",
    "\n",
    "option_a = 0\n",
    "option_b = 0\n",
    "option_c = 0\n",
    "option_d = 0\n",
    "option_e = 0\n",
    "\n",
    "for i in range(100):\n",
    "    x_value = random.uniform(-1, 1)\n",
    "           \n",
    "    y_value = random.uniform(-1, 1)\n",
    "                    \n",
    "    new = [1, x_value, y_value, x_value * y_value, x_value ** 2, y_value ** 2]\n",
    "    \n",
    "    test_z = matrix(new)\n",
    "    \n",
    "    outcome = weight.T * test_z.T\n",
    "    \n",
    "    if OptionA(x_value, y_value) == numpy.sign(outcome):\n",
    "        option_a += 1\n",
    "    if OptionB(x_value, y_value) == numpy.sign(outcome):\n",
    "        option_b += 1\n",
    "    if OptionC(x_value, y_value) == numpy.sign(outcome):\n",
    "        option_c += 1\n",
    "    if OptionD(x_value, y_value) == numpy.sign(outcome):\n",
    "        option_d += 1\n",
    "    if OptionE(x_value, y_value) == numpy.sign(outcome):\n",
    "        option_e += 1\n",
    "        \n",
    "print(option_a)\n",
    "print(option_b)\n",
    "print(option_c)\n",
    "print(option_d)\n",
    "print(option_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064\n"
     ]
    }
   ],
   "source": [
    "# Now, we will find the average E_out for this hypothesis over 1000 runs. Answer to number 10.\n",
    "\n",
    "new_set = NonlinearPointGenerator(1000)\n",
    "outcomes = PointClassifier(new_set)\n",
    "counter = 0\n",
    "for i in range(1000):\n",
    "    if numpy.sign(-1 - .05 * new_set[i][1] + .08 * new_set[i][2] + 0.13 * new_set[i][3]\n",
    "                  + 1.5 * new_set[i][4] + 1.5 * new_set[i][5]) != outcomes[i]:\n",
    "        counter += 1\n",
    "average = counter / 1000\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
